<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>From ProGAN to StyleGAN - Yuthon&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Yusu Pan" /><meta name="description" content="In this post, we are looking into two high-resolution image generation models: ProGAN and StyleGAN. They generates the artificial image gradually, starting from a very low resolution and continuing to a high resolution (finally $1024\times 1024​$).
" /><meta name="keywords" content="yuthon, yusu-pan, blog, deep-learning, computer-vision" />






<meta name="generator" content="Hugo 0.54.0 with even 4.0.0" />


<link rel="canonical" href="https://www.yuthon.com/post/tutorials/from-progan-to-stylegan/" />
<link rel="apple-touch-icon" sizes="180x180" href="https://www.yuthon.com/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.yuthon.com/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.yuthon.com/favicon-16x16.png">
<link rel="manifest" href="https://www.yuthon.com/manifest.json">
<link rel="mask-icon" href="https://www.yuthon.com/safari-pinned-tab.svg" color="#5bbad5">


<link href="https://www.yuthon.com/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="From ProGAN to StyleGAN" />
<meta property="og:description" content="In this post, we are looking into two high-resolution image generation models: ProGAN and StyleGAN. They generates the artificial image gradually, starting from a very low resolution and continuing to a high resolution (finally $1024\times 1024​$)." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.yuthon.com/post/tutorials/from-progan-to-stylegan/" />
<meta property="article:published_time" content="2018-02-26T19:42:13&#43;08:00"/>
<meta property="article:modified_time" content="2018-12-31T19:42:13&#43;08:00"/>

<meta itemprop="name" content="From ProGAN to StyleGAN">
<meta itemprop="description" content="In this post, we are looking into two high-resolution image generation models: ProGAN and StyleGAN. They generates the artificial image gradually, starting from a very low resolution and continuing to a high resolution (finally $1024\times 1024​$).">


<meta itemprop="datePublished" content="2018-02-26T19:42:13&#43;08:00" />
<meta itemprop="dateModified" content="2018-12-31T19:42:13&#43;08:00" />
<meta itemprop="wordCount" content="3394">



<meta itemprop="keywords" content="GANs,Image Generation," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="From ProGAN to StyleGAN"/>
<meta name="twitter:description" content="In this post, we are looking into two high-resolution image generation models: ProGAN and StyleGAN. They generates the artificial image gradually, starting from a very low resolution and continuing to a high resolution (finally $1024\times 1024​$)."/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="https://www.yuthon.com/" class="logo">Yuthon&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="https://www.yuthon.com/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="https://www.yuthon.com/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="https://www.yuthon.com/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="https://www.yuthon.com/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="https://www.yuthon.com/resume/">
        <li class="mobile-menu-item">Resume</li>
      </a><a href="https://github.com/corenel">
        <li class="mobile-menu-item">Works</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="https://www.yuthon.com/" class="logo">Yuthon&#39;s Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/resume/">Resume</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://github.com/corenel">Works</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">From ProGAN to StyleGAN</h1>

      <div class="post-meta">
        <span class="post-time"> 2018-02-26 </span>
        <div class="post-category">
            <a href="https://www.yuthon.com/categories/notes/"> Notes </a>
            <a href="https://www.yuthon.com/categories/tutorials/"> Tutorials </a>
            </div>
          <span class="more-meta"> 3394 words </span>
          <span class="more-meta"> 7 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content always-active">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#progan">ProGAN</a>
<ul>
<li><a href="#workflow">Workflow</a></li>
<li><a href="#details">Details</a>
<ul>
<li><a href="#fading-in-new-layers">Fading in new layers</a></li>
<li><a href="#minibatch-standard-deviation">Minibatch Standard Deviation</a></li>
<li><a href="#torgb-fromrgb">toRGB &amp; fromRGB</a></li>
<li><a href="#loss-function">Loss function</a></li>
</ul></li>
<li><a href="#tricks">Tricks</a>
<ul>
<li><a href="#upscale-2x">Upscale 2x</a></li>
<li><a href="#equalized-learning-rate">Equalized Learning Rate</a></li>
<li><a href="#pixel-normalization">Pixel Normalization</a></li>
</ul></li>
<li><a href="#drawbacks">Drawbacks</a></li>
</ul></li>
<li><a href="#stylegan">StyleGAN</a></li>
<li><a href="#reference">Reference</a></li>
</ul></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>In this post, we are looking into two high-resolution image generation models: ProGAN and StyleGAN. They generates the artificial image gradually, starting from a very low resolution and continuing to a high resolution (finally $1024\times 1024​$).</p>

<table>
<thead>
<tr>
<th>Model</th>
<th>Resources</th>
</tr>
</thead>

<tbody>
<tr>
<td>ProGAN</td>
<td>[<a href="https://arxiv.org/abs/1710.10196">paper</a>] [<a href="https://github.com/tkarras/progressive_growing_of_gans">code (TensorFlow, Official)</a>]</td>
</tr>

<tr>
<td>StyleGAN</td>
<td>[<a href="https://arxiv.org/abs/1812.04948">paper</a>] [<a href="https://github.com/NVlabs/stylegan">code (TensorFlow, Official)</a>]</td>
</tr>
</tbody>
</table>

<h2 id="progan">ProGAN</h2>

<p>NVIDIA在2017年底推出的ProGAN解决了GANs生成高质量高分辨率图像的难题。其核心思想在于渐进式的训练方法（Progressive training）。网络从一个非常低的分辨率（如$4\times 4$）开始，逐步训练并增大图像分辨率，直到生成器能够生成的图像分辨率达到目标的高分辨率（如$1024\times 1024$）。</p>

<figure class="zoomable">
    <img src="https://www.yuthon.com/images/ProGAN_demo.gif"/> <figcaption>
            <h4>ProGAN从低分辨率到高分辨率的渐进式训练示意图 (Source: Sarah Wolf’s blog post on ProGAN)</h4>
        </figcaption>
</figure>


<p>使用渐进式生长训练方式的优势在于：</p>

<ul>
<li>将高分辨率图像生成这样一个复杂的任务，分解为一系列相对简单的任务。这种增量式的学习过程能够很大程度上稳定GANs的训练，并且减少mode collapse现象。</li>
<li>从低分辨率到高分辨率的训练，能够使网络先着眼于在低分辨率图像中也能体现的高层级的图像结构与特征，然后再向其中填充细节。这保证了网络不会在高层级的图像结构中犯大错误，从而提升了生成图像的质量。</li>
<li>此外，渐进生长方式在计算上也比从一开始就训练整个网络的传统方法更为有效。开始时，训练图像分辨率低，网络的层数少，参数量也少，因此网络能够快速收敛。在达到目标分辨率之前，网络都是只有一部分在训练，因此在效率上是有提升的。ProGAN原文中指出，随着目标分辨率的不同，ProGAN的训练速度比传统方法快2至6倍。</li>
</ul>

<figure>
    <img src="https://www.yuthon.com/images/ProGAN_training_time.jpg"/> <figcaption>
            <h4>ProGAN训练时间 (Source: original paper)</h4>
        </figcaption>
</figure>


<h3 id="workflow">Workflow</h3>

<figure>
    <img src="https://www.yuthon.com/images/ProGAN_architecture.jpg"/> <figcaption>
            <h4>ProGAN网络结构 (Source: original paper)</h4>
        </figcaption>
</figure>


<ol>
<li><strong>构建整个ProGAN网络。</strong>ProGAN的网络架构是多尺度的。Generator的每一组都将空间尺寸扩大到原先的两倍，通道数则减少为原先的一半。直到特征的空间尺寸达到目标尺寸，通道数则减少到$3$，及RGB三个通道。Discriminator的网络结构则基本上是Generator的镜像，每一组都减半空间尺寸，倍增通道数。同时，为了保证总参数量不至于过高，倍增得到的通道数的上限设为$512$。</li>
<li><strong>按照分辨率从低到高逐步训练ProGAN网络。</strong>从$4\times 4​$的网络开始训练，稳定后增长分辨率，Generator与Discriminator同时增加一组卷积层，首先进入Fade-in模式，之后进入Stabilize模式。<u>当增加新的卷积层后，原有层内的参数仍然保持可训练的状态。</u>稳定后，继续增大分辨率，如上述进行训练。如此反复，直到达到目标分辨率。</li>
</ol>

<h3 id="details">Details</h3>

<h4 id="fading-in-new-layers">Fading in new layers</h4>

<figure class="zoomable">
    <img src="https://www.yuthon.com/images/ProGAN_generator.png"/> <figcaption>
            <h4>ProGAN网络Generator结构与增长分辨率时的Fade-in策略 (Source: Sarah Wolf’s blog post on ProGAN)</h4>
        </figcaption>
</figure>


<figure class="zoomable">
    <img src="https://www.yuthon.com/images/ProGAN_discriminator.png"/> <figcaption>
            <h4>ProGAN网络Discriminator结构 (Source: [DL輪読会]Progressive Growing of GANs for Improved Quality, Stability, and Variation)</h4>
        </figcaption>
</figure>


<p>当增大分辨率时，Generator与Discriminator都会增加卷积层。为了让新加层快速收敛，同时又不对原有层造成过大的影响，ProGAN提出了一种Fade-in的机制。如上图所示，在Fade-in阶段时，旧有的层的输出经过上采样放大两倍，而后通过<code>toRGB</code>层转化为RGB图像，与新加层的输出通过<code>toRGB</code>层转化后的图像进行加权和，形成最终的输出。这一融合由一个参数$\alpha$进行控制，$x&rsquo;=\alpha x_{i-1} + (1-\alpha) x_i$。随着训练的进行，$\alpha$从$1$线性减少为$0$，最终输出也逐渐转为新加层的输出占主导。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># fade-in phase in generator</span>
<span class="n">upsample</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">interpolate</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;nearest&#39;</span><span class="p">,</span> <span class="n">align_corners</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">progression</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_rgb</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>
<span class="n">skip_rgb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">to_rgb</span><span class="p">[</span><span class="n">i</span> <span class="o">-</span> <span class="mi">1</span><span class="p">](</span><span class="n">upsample</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">skip_rgb</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">out</span>

<span class="c1"># fade-in phase in discriminator</span>
<span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">progression</span><span class="p">[</span><span class="n">i</span><span class="p">](</span><span class="n">out</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">downsample</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">avg_pool2d</span><span class="p">(</span><span class="nb">input</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">skip_rgb</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">from_rgb</span><span class="p">[</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">](</span><span class="n">downsample</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">alpha</span><span class="p">)</span> <span class="o">*</span> <span class="n">skip_rgb</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">out</span></code></pre></td></tr></table>
</div>
</div>
<h4 id="minibatch-standard-deviation">Minibatch Standard Deviation</h4>

<figure class="zoomable">
    <img src="https://www.yuthon.com/images/ProGAN_minibatch_std.png"/> <figcaption>
            <h4>ProGAN网络Discrimiantor中的minibatch standard deviation层 (Source: Sarah Wolf’s blog post on ProGAN)</h4>
        </figcaption>
</figure>


<p>ProGAN为了解决GANs生成的图像多样性较差的问题，在discriminator的最后增加了一个minibatch standard deviation层。  这个层没有需要训练的参数，其作用为求取minibatch内的所有feature maps ($N\times H\times W \times 3$)上各个像素位置对应的标准差，将这些逐像素的标准差拼起来，组成一张新的feature map ($1\times H\times W \times1 $)作为新的通道加入。这有助于统计minibatch内的信息，让discriminator根据这些额外的统计信息来区分真是样本的batch与生成样本的batch。从而让generator需要生成更加多样化、更加接近真实样本分布的样本来“骗过”discriminator，最终达到增强generator生成多样化样本的目的。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="n">out_std</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">var</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">unbiased</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span>
<span class="n">mean_std</span> <span class="o">=</span> <span class="n">out_std</span><span class="o">.</span><span class="n">mean</span><span class="p">()</span>
<span class="n">mean_std</span> <span class="o">=</span> <span class="n">mean_std</span><span class="o">.</span><span class="n">expand</span><span class="p">(</span><span class="n">out</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">4</span><span class="p">)</span>
<span class="n">out</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cat</span><span class="p">([</span><span class="n">out</span><span class="p">,</span> <span class="n">mean_std</span><span class="p">],</span> <span class="mi">1</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<h4 id="torgb-fromrgb">toRGB &amp; fromRGB</h4>

<p>在训练过程中，Generator的输出以及Discriminator的输入需要为RGB图像，这就需要使用$1\times 1$的卷积将在多通道的feature maps与3通道的图像之间进行转换。这就是<code>toRGB</code>（Generator最后一层卷积层）与<code>fromRGB</code>层（Discriminator第一层卷积层）的由来。当然，针对不同分辨率的<code>toRGB</code>层与<code>fromRGB</code>层是不同尺寸的，且是单独训练的。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="c1"># toRGB layers in generator</span>
<span class="n">to_rgb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">512</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">256</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                        <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">128</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span>
<span class="c1"># fromRGB layers in discriminator</span>
<span class="n">from_rgb</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">ModuleList</span><span class="p">([</span><span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">128</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">256</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
                          <span class="n">EqualConv2d</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">512</span><span class="p">,</span> <span class="mi">1</span><span class="p">)])</span></code></pre></td></tr></table>
</div>
</div>
<h4 id="loss-function">Loss function</h4>

<p>ProGAN使用的是<a href="https://arxiv.org/abs/1704.00028">WGAN-GP</a>，介绍可参见<a href="https://www.yuthon.com/post/tutorials/something-about-gans/#wgan-gp-1">之前的文章</a>。其损失函数形式为：</p>

<p>$$
\begin{aligned}
\mathcal{L}_G &amp;= -D(x&rsquo;) <br />
\mathcal{L}_D &amp;= -D(x) + D(x&rsquo;) + \lambda \times GP <br />
GP &amp;= \left(||\nabla D (\alpha x&rsquo; + (1 - \alpha)x ))||_2 - 1 \right)^2 <br />
\end{aligned}
$$</p>

<p>其中，$D$为Discriminator，$x$、$x&rsquo;$分别为真实样本与生成样本。$\lambda=10$为权重项，$GP$为用于稳定训练的梯度惩罚项，$\alpha \in (0,1)$为均匀采样的随机数，用以表示$x$与$x&rsquo;$的加权平均（即其连线上的任意一点）。</p>

<h3 id="tricks">Tricks</h3>

<h4 id="upscale-2x">Upscale 2x</h4>

<p>在放大特征图的方法上，与DCGAN等使用转置卷积（transpose convolutions）不同，ProGAN用最近邻插值来视线上采样，用average pooling来降采样。这两种方法均不需要可学习的参数，更为简单。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.nn</span> <span class="kn">import</span> <span class="n">functional</span> <span class="k">as</span> <span class="n">F</span>

<span class="c1"># upsample = nn.F.interpolate(out, scale_factor=2, mode=&#39;nearest&#39;, align_corners=False)</span>
<span class="n">upsampler</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">UpsamplingNearest2d</span><span class="p">(</span><span class="n">scale_factor</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span>
<span class="c1"># downsample = F.avg_pool2d(out, 2)</span>
<span class="n">downsampler</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">AvgPool2d</span><span class="p">(</span><span class="n">kernel_size</span><span class="o">=</span><span class="mi">2</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<h4 id="equalized-learning-rate">Equalized Learning Rate</h4>

<p>为了保证Generator与Discriminator之间的良性竞争，ProGAN指出需要使得各个卷积层以相似的速度进行学习。为了达到equlized learnig rate，ProGAN采用了与<a href="https://arxiv.org/abd/1502.01852">He initialization</a>相似的方法，也就是将每个层的权重乘以其权重参数量。而且不仅仅是初始化权重时这么做，在训练过程的每次forwarding时都进行此操作。</p>

<p>$$
W = W_{orig} \times \sqrt{\frac{2}{\text{fan_in}}}
$$</p>

<p>其中$W_{orig}$、$W$分别为原始权重与实际使用的权重，对于卷积层来说，$\text{fan_in} = k\times k \times c$$k$为kernel大小，$c$为</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt"> 1
</span><span class="lnt"> 2
</span><span class="lnt"> 3
</span><span class="lnt"> 4
</span><span class="lnt"> 5
</span><span class="lnt"> 6
</span><span class="lnt"> 7
</span><span class="lnt"> 8
</span><span class="lnt"> 9
</span><span class="lnt">10
</span><span class="lnt">11
</span><span class="lnt">12
</span><span class="lnt">13
</span><span class="lnt">14
</span><span class="lnt">15
</span><span class="lnt">16
</span><span class="lnt">17
</span><span class="lnt">18
</span><span class="lnt">19
</span><span class="lnt">20
</span><span class="lnt">21
</span><span class="lnt">22
</span><span class="lnt">23
</span><span class="lnt">24
</span><span class="lnt">25
</span><span class="lnt">26
</span><span class="lnt">27
</span><span class="lnt">28
</span><span class="lnt">29
</span><span class="lnt">30
</span><span class="lnt">31
</span><span class="lnt">32
</span><span class="lnt">33
</span><span class="lnt">34
</span><span class="lnt">35
</span><span class="lnt">36
</span><span class="lnt">37
</span><span class="lnt">38
</span><span class="lnt">39
</span><span class="lnt">40
</span><span class="lnt">41
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">EqualLR</span><span class="p">:</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">=</span> <span class="n">name</span>

    <span class="k">def</span> <span class="nf">compute_weight</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_orig&#39;</span><span class="p">)</span>
        <span class="n">fan_in</span> <span class="o">=</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">size</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span> <span class="o">*</span> <span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">[</span><span class="mi">0</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numel</span><span class="p">()</span>

        <span class="k">return</span> <span class="n">weight</span> <span class="o">*</span> <span class="n">sqrt</span><span class="p">(</span><span class="mi">2</span> <span class="o">/</span> <span class="n">fan_in</span><span class="p">)</span>

    <span class="nd">@staticmethod</span>
    <span class="k">def</span> <span class="nf">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">):</span>
        <span class="n">fn</span> <span class="o">=</span> <span class="n">EqualLR</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>

        <span class="n">weight</span> <span class="o">=</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
        <span class="k">del</span> <span class="n">module</span><span class="o">.</span><span class="n">_parameters</span><span class="p">[</span><span class="n">name</span><span class="p">]</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_parameter</span><span class="p">(</span><span class="n">name</span> <span class="o">+</span> <span class="s1">&#39;_orig&#39;</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Parameter</span><span class="p">(</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="p">))</span>
        <span class="n">module</span><span class="o">.</span><span class="n">register_forward_pre_hook</span><span class="p">(</span><span class="n">fn</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">fn</span>

    <span class="k">def</span> <span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">module</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
        <span class="n">weight</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">compute_weight</span><span class="p">(</span><span class="n">module</span><span class="p">)</span>
        <span class="nb">setattr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">name</span><span class="p">,</span> <span class="n">weight</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">equal_lr</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="o">=</span><span class="s1">&#39;weight&#39;</span><span class="p">):</span>
    <span class="n">EqualLR</span><span class="o">.</span><span class="nb">apply</span><span class="p">(</span><span class="n">module</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">module</span>


<span class="k">class</span> <span class="nc">EqualConv2d</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

        <span class="n">conv</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Conv2d</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>
        <span class="n">conv</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">normal_</span><span class="p">()</span>
        <span class="n">conv</span><span class="o">.</span><span class="n">bias</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">zero_</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">conv</span> <span class="o">=</span> <span class="n">equal_lr</span><span class="p">(</span><span class="n">conv</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">conv</span><span class="p">(</span><span class="n">input_tensor</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<h4 id="pixel-normalization">Pixel Normalization</h4>

<p>ProGAN没有使用BN层，而是提出了Pixel Normalization层。与BN层类似，PN层直接放在卷积层之后，激活函数之前。这个层没有需要训练的参数，其作用为将feature maps中的每个像素位置$(x,y)$在不同的通道$C​$上的值都归一化到单位长度：</p>

<div>
$$
b_{x,y} = \frac{a_{x,y}}{\sqrt{\frac{1}{C} \sum^C_{j=0} a_{x,y}^j+\epsilon}}
$$
</div>

<p>其中，$a$、$b$分别为输入张量与输出张量，$\epsilon=10^{-8}$为防止除以零的常数。这一举措能够防止像素位置上的信号响应在训练过程中失控，可以提升训练时的稳定性。</p>
<div class="highlight"><div class="chroma">
<table class="lntable"><tr><td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="lnt">1
</span><span class="lnt">2
</span><span class="lnt">3
</span><span class="lnt">4
</span><span class="lnt">5
</span><span class="lnt">6
</span><span class="lnt">7
</span></code></pre></td>
<td class="lntd">
<pre class="chroma"><code class="language-python" data-lang="python"><span class="k">class</span> <span class="nc">PixelNorm</span><span class="p">(</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">input_tensor</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">input_tensor</span> <span class="o">/</span> <span class="n">torch</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">input_tensor</span> <span class="o">**</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dim</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">keepdim</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span> <span class="o">+</span> <span class="mf">1e-8</span><span class="p">)</span></code></pre></td></tr></table>
</div>
</div>
<h3 id="drawbacks">Drawbacks</h3>

<p>ProGAN虽然能够生成高质量高分辨率的图像，但是其本质上还是一种无条件（unconditional）的生成方法。其难以控制所生成图像的属性。并且就算是修改输入的随机向量，其微小的变化也会引起最终生成图像中的多个属性一起变化。如何将ProGAN改为有条件（conditional）的生成模型，或者增强其微调单个属性的能力，这是一个可以研究的方向。</p>

<h2 id="stylegan">StyleGAN</h2>

<p>StyleGAN是NVIDIA继ProGAN之后提出的新的生成网络，其主要通过分别修改每一层级的输入，来控制</p>

<p>(to be continued)</p>

<h2 id="reference">Reference</h2>

<ul>
<li><a href="https://towardsdatascience.com/progan-how-nvidia-generated-images-of-unprecedented-quality-51c98ec2cbd2">ProGAN: How NVIDIA Generated Images of Unprecedented Quality</a></li>
<li><a href="https://towardsdatascience.com/progressively-growing-gans-9cb795caebee">Progressively-Growing GANs Review</a></li>
<li><a href="https://towardsdatascience.com/explained-a-style-based-generator-architecture-for-gans-generating-and-tuning-realistic-6cb2be0f431">Explained: A Style-Based Generator Architecture for GANs - Generating and Tuning Realistic Artificial Faces</a></li>
<li><a href="rosinality/style-based-gan-pytorch">rosinality/style-based-gan-pytorch</a></li>
</ul>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Yusu Pan</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2018-12-31
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="https://www.yuthon.com/tags/gans/">GANs</a>
          <a href="https://www.yuthon.com/tags/image-generation/">Image Generation</a>
          </div>
      <nav class="post-nav">
        
        <a class="next" href="https://www.yuthon.com/post/papers/notes-for-adversarial-discriminative-domain-adaptation/">
            <span class="next-text nav-default">Notes for Adversarial Discriminative Domain Adaptation</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'yuthons-blog';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:xxdsox@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://stackoverflow.com/users/5682817" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://twitter.com/corenel" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.facebook.com/xxdsox" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://github.com/corenel" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/pan-yu-su" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="https://www.yuthon.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License, please give source if you wish to quote or reproduce.
</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://www.yuthon.com/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: {equationNumbers: {autoNumber: "AMS"}},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-76233259-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
