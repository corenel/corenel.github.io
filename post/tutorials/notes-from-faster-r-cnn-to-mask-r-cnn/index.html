<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
  <title>Notes: From Faster R-CNN to Mask R-CNN - Yuthon&#39;s Blog</title>
  <meta name="renderer" content="webkit" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>

<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />

<meta name="theme-color" content="#f8f5ec" />
<meta name="msapplication-navbutton-color" content="#f8f5ec">
<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="#f8f5ec">


<meta name="author" content="Yusu Pan" /><meta name="description" content="That&amp;rsquo;s my notes for the talk &amp;ldquo;From Faster-RCNN to Mask-RCNN&amp;rdquo; by Shaoqing Ren on April 26th, 2017.
Yesterday – background and pre-works of Mask R-CNN Key functions  Classification - What are in the image? Localization - Where are they? Mask (per pixel) classification - Where&#43; ?  More precise to bounding box  Landmarks localization - What&#43;, Where&#43; ?  Not only per-pixel mask, but also key points in the objects  " /><meta name="keywords" content="yuthon, yusu-pan, blog, deep-learning, computer-vision" />






<meta name="generator" content="Hugo 0.54.0 with even 4.0.0" />


<link rel="canonical" href="https://www.yuthon.com/post/tutorials/notes-from-faster-r-cnn-to-mask-r-cnn/" />
<link rel="apple-touch-icon" sizes="180x180" href="https://www.yuthon.com/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="https://www.yuthon.com/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="https://www.yuthon.com/favicon-16x16.png">
<link rel="manifest" href="https://www.yuthon.com/manifest.json">
<link rel="mask-icon" href="https://www.yuthon.com/safari-pinned-tab.svg" color="#5bbad5">


<link href="https://www.yuthon.com/dist/even.c2a46f00.min.css" rel="stylesheet">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.css" integrity="sha256-7TyXnr2YU040zfSP+rEcz29ggW4j56/ujTPwjMzyqFY=" crossorigin="anonymous">


<meta property="og:title" content="Notes: From Faster R-CNN to Mask R-CNN" />
<meta property="og:description" content="That&rsquo;s my notes for the talk &ldquo;From Faster-RCNN to Mask-RCNN&rdquo; by Shaoqing Ren on April 26th, 2017.

Yesterday – background and pre-works of Mask R-CNN

Key functions


Classification - What are in the image?
Localization - Where are they?
Mask (per pixel) classification - Where&#43; ?


More precise to bounding box

Landmarks localization - What&#43;, Where&#43; ?


Not only per-pixel mask, but also key points in the objects

" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://www.yuthon.com/post/tutorials/notes-from-faster-r-cnn-to-mask-r-cnn/" />
<meta property="article:published_time" content="2017-04-27T12:55:33&#43;00:00"/>
<meta property="article:modified_time" content="2017-04-27T12:55:33&#43;00:00"/>

<meta itemprop="name" content="Notes: From Faster R-CNN to Mask R-CNN">
<meta itemprop="description" content="That&rsquo;s my notes for the talk &ldquo;From Faster-RCNN to Mask-RCNN&rdquo; by Shaoqing Ren on April 26th, 2017.

Yesterday – background and pre-works of Mask R-CNN

Key functions


Classification - What are in the image?
Localization - Where are they?
Mask (per pixel) classification - Where&#43; ?


More precise to bounding box

Landmarks localization - What&#43;, Where&#43; ?


Not only per-pixel mask, but also key points in the objects

">


<meta itemprop="datePublished" content="2017-04-27T12:55:33&#43;00:00" />
<meta itemprop="dateModified" content="2017-04-27T12:55:33&#43;00:00" />
<meta itemprop="wordCount" content="1210">



<meta itemprop="keywords" content="Object Detection,Semantic Segmentation,Faster R-CNN,Mask R-CNN," />
<meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Notes: From Faster R-CNN to Mask R-CNN"/>
<meta name="twitter:description" content="That&rsquo;s my notes for the talk &ldquo;From Faster-RCNN to Mask-RCNN&rdquo; by Shaoqing Ren on April 26th, 2017.

Yesterday – background and pre-works of Mask R-CNN

Key functions


Classification - What are in the image?
Localization - Where are they?
Mask (per pixel) classification - Where&#43; ?


More precise to bounding box

Landmarks localization - What&#43;, Where&#43; ?


Not only per-pixel mask, but also key points in the objects

"/>

<!--[if lte IE 9]>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/classlist/1.1.20170427/classList.min.js"></script>
<![endif]-->

<!--[if lt IE 9]>
  <script src="https://cdn.jsdelivr.net/npm/html5shiv@3.7.3/dist/html5shiv.min.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/respond.js@1.4.2/dest/respond.min.js"></script>
<![endif]-->

</head>
<body>
  <div id="mobile-navbar" class="mobile-navbar">
  <div class="mobile-header-logo">
    <a href="https://www.yuthon.com/" class="logo">Yuthon&#39;s Blog</a>
  </div>
  <div class="mobile-navbar-icon">
    <span></span>
    <span></span>
    <span></span>
  </div>
</div>
<nav id="mobile-menu" class="mobile-menu slideout-menu">
  <ul class="mobile-menu-list">
    <a href="https://www.yuthon.com/">
        <li class="mobile-menu-item">Home</li>
      </a><a href="https://www.yuthon.com/categories/">
        <li class="mobile-menu-item">Categories</li>
      </a><a href="https://www.yuthon.com/tags/">
        <li class="mobile-menu-item">Tags</li>
      </a><a href="https://www.yuthon.com/about/">
        <li class="mobile-menu-item">About</li>
      </a><a href="https://www.yuthon.com/resume/">
        <li class="mobile-menu-item">Resume</li>
      </a><a href="https://github.com/corenel">
        <li class="mobile-menu-item">Works</li>
      </a>
  </ul>
</nav>
  <div class="container" id="mobile-panel">
    <header id="header" class="header">
        <div class="logo-wrapper">
  <a href="https://www.yuthon.com/" class="logo">Yuthon&#39;s Blog</a>
</div>

<nav class="site-navbar">
  <ul id="menu" class="menu">
    <li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/">Home</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/categories/">Categories</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/tags/">Tags</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/about/">About</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://www.yuthon.com/resume/">Resume</a>
      </li><li class="menu-item">
        <a class="menu-item-link" href="https://github.com/corenel">Works</a>
      </li>
  </ul>
</nav>
    </header>

    <main id="main" class="main">
      <div class="content-wrapper">
        <div id="content" class="content">
          <article class="post">
    
    <header class="post-header">
      <h1 class="post-title">Notes: From Faster R-CNN to Mask R-CNN</h1>

      <div class="post-meta">
        <span class="post-time"> 2017-04-27 </span>
        <div class="post-category">
            <a href="https://www.yuthon.com/categories/notes/"> Notes </a>
            <a href="https://www.yuthon.com/categories/tutorials/"> Tutorials </a>
            </div>
          <span class="more-meta"> 1210 words </span>
          <span class="more-meta"> 6 mins read </span>
        
      </div>
    </header>

    <div class="post-toc" id="post-toc">
  <h2 class="post-toc-title">Contents</h2>
  <div class="post-toc-content">
    <nav id="TableOfContents">
<ul>
<li>
<ul>
<li><a href="#yesterday-background-and-pre-works-of-mask-r-cnn">Yesterday – background and pre-works of Mask R-CNN</a>
<ul>
<li><a href="#key-functions">Key functions</a></li>
<li><a href="#mask-r-cnn-architecture">Mask R-CNN Architecture</a></li>
<li><a href="#classification">Classification</a>
<ul>
<li><a href="#problems">Problems</a></li>
<li><a href="#solutions">Solutions</a></li>
</ul></li>
<li><a href="#detection">Detection</a>
<ul>
<li><a href="#problems-1">Problems</a></li>
<li><a href="#solutions-1">Solutions</a></li>
<li><a href="#r-cnn">R-CNN</a></li>
<li><a href="#spp-net-fast-r-cnn">SPP-net / Fast R-CNN</a></li>
<li><a href="#faster-r-cnn">Faster R-CNN</a></li>
<li><a href="#ssd-fpn">SSD / FPN</a></li>
</ul></li>
<li><a href="#instance-segmentation">Instance Segmentation</a></li>
<li><a href="#keypoint-detection">Keypoint Detection</a></li>
</ul></li>
<li><a href="#today-details-about-mask-rcnn-and-comparisons">Today - details about Mask-RCNN and comparisons</a>
<ul>
<li><a href="#roi-align">RoI Align</a></li>
<li><a href="#multinomial-vs-independent-masks">Multinomial vs. Independent Masks</a></li>
<li><a href="#multi-task-cascade-vs-joint-learning">Multi-task Cascade vs. Joint Learning</a></li>
<li><a href="#comparison-on-human-keypoints">Comparison on Human Keypoints</a></li>
<li><a href="#results">Results</a></li>
</ul></li>
<li><a href="#future-discussion">Future - discussion</a>
<ul>
<li><a href="#order-of-key-functions">Order of key functions?</a></li>
<li><a href="#precious-semantic-label">Precious &amp; semantic label</a></li>
<li><a href="#semantic-3d-reconstruction">Semantic 3D reconstruction</a></li>
<li><a href="#future">Future</a></li>
</ul></li>
</ul></li>
</ul>
</nav>
  </div>
</div>
    <div class="post-content">
      <p>That&rsquo;s my notes for the talk &ldquo;From Faster-RCNN to Mask-RCNN&rdquo; by Shaoqing Ren on April 26th, 2017.</p>

<h2 id="yesterday-background-and-pre-works-of-mask-r-cnn">Yesterday – background and pre-works of Mask R-CNN</h2>

<h3 id="key-functions">Key functions</h3>

<ul>
<li><strong>Classification</strong> - What are in the image?</li>
<li><strong>Localization</strong> - Where are they?</li>
<li><strong>Mask (per pixel) classification</strong> - Where+ ?

<ul>
<li>More precise to bounding box</li>
</ul></li>
<li><strong>Landmarks localization</strong> - What+, Where+ ?

<ul>
<li>Not only per-pixel mask, but also key points in the objects</li>
</ul></li>
</ul>

<h3 id="mask-r-cnn-architecture">Mask R-CNN Architecture</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_architecture_of_mask_r-cnn.jpg" alt="Mask R-CNN Architecture" /></p>

<h3 id="classification">Classification</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_classification_cnn.jpg" alt="CNN for classification" /></p>

<blockquote>
<p>Please ignoring the bounding box in the image</p>
</blockquote>

<p>$$
\text{class} = Classifier(\text{image})
$$</p>

<h4 id="problems">Problems</h4>

<ul>
<li>High-level semantic concepts</li>
<li>High efficiency</li>
</ul>

<h4 id="solutions">Solutions</h4>

<ul>
<li><strong>SIFT</strong> or <strong>HOG</strong> (about 5 or 10 years ago)

<ul>
<li>Based on edge feature (low- level semantic infomations)</li>
<li>Sometimes mistake two objects which people can distinguish easily</li>
<li>e.g.  mark the telegraph pole as a man</li>
</ul></li>
<li><strong>CNN</strong> (nowadays)

<ul>
<li>Based on high-level semantic concepts</li>
<li>Rarely mistake objects. If it do so, people are likely to mix up them, too.</li>
<li>Translation invariance</li>
<li>Scale invariance</li>
</ul></li>
</ul>

<h3 id="detection">Detection</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_detection_concept.jpg" alt="Detection Concept" />
$$
\text{location}=Classifier(\text{all patches of an image)} <br />
\text{precise_location}=Regressor(\text{image}, \text{rough_location})
$$</p>

<h4 id="problems-1">Problems</h4>

<ul>
<li>High efficiency</li>
</ul>

<h4 id="solutions-1">Solutions</h4>

<ul>
<li><strong>Traverse</strong> all patches of an image and apply image classifier on them, then patches with highest scores are looked as locations of objects.

<ul>
<li>As long as the classifier is precise enough, and we are able to traverse millions of patches in an image, we can always get a satisfactory result.</li>
<li>But the amount of calculations is too large. (about 1 or 10 millon)</li>
</ul></li>
<li>Do <strong>Regression</strong> cosntantlty, starting from a rough location of an object, and finally we&rsquo;ll get the precise object location.

<ul>
<li>Low amount of calculations. (about 10 or 100 times)</li>
<li>Hard to locate many adjacent and similar objects</li>
</ul></li>
<li>The state-of-the-art methods tend to use exhaustion on large-scale, and refine the rough localtions by regression on small-scale.</li>
</ul>

<h4 id="r-cnn">R-CNN</h4>

<p><img src="https://www.yuthon.com/images/FFRMR_detection_rcnn.jpg" alt="RCNN" /></p>

<ul>
<li>Use <strong>region proposal</strong> to decline millions of patches into 2~10k.</li>
<li>Use classifier to determine the class of a patch</li>
<li>Use BBox regression to refine the location</li>
</ul>

<h4 id="spp-net-fast-r-cnn">SPP-net / Fast R-CNN</h4>

<p><img src="https://www.yuthon.com/images/FFRMR_SPP_net_1.jpg" alt="SPP-net 1" /></p>

<p><img src="https://www.yuthon.com/images/FFRMR_SPP_net_2.jpg" alt="SPP-net 2" /></p>

<ul>
<li>Use <strong>Pyramid Pooling / RoI-Pooling</strong> to generate a fixed-length representation regardless of image size/scale</li>
</ul>

<h4 id="faster-r-cnn">Faster R-CNN</h4>

<p><img src="https://www.yuthon.com/images/FFRMR_Faster-RCNN_1.jpg" alt="Faster-RCNN" /></p>

<ul>
<li>Use <strong>RPN</strong> (Region Proposal Network) that shares full-image convolutional features with the detection network, thus enabling nearly cost-free region proposals.

<ul>
<li>An RPN is a fully convolutional network that simultaneously predicts object bounds and objectness scores at each position.</li>
<li>The RPN is trained end-to-end to generate high-quality region proposals, which are used by Fast R-CNN for detection.</li>
<li>We further merge RPN and Fast R-CNN into a single network by sharing their convolutional features&mdash;using the recently popular terminology of neural networks with &lsquo;attention&rsquo; mechanisms, the RPN component tells the unified network where to look.</li>
</ul></li>
<li>Number of patches: $width \times height \times scales \times ratios$

<ul>
<li><code>scale</code> stands for the size of image and objects</li>
<li><code>ratio</code> stands for the aspect ratio of filter</li>
</ul></li>
</ul>

<p><img src="https://www.yuthon.com/images/FFRMR_multiple_scales_ratios.jpg" alt="Multiple scales / ratios" /></p>

<p>Different schemes for addressing multiple scales and sizes.</p>

<ul>
<li>Pyramids of images and feature maps are built, and the classifier is run at all scales.</li>
<li>Pyramids of filters with multiple scales/sizes are run on the feature map.</li>
<li>Faster R-CNN use pyramids of reference boxes in the regression functions, which avoids enumerating images or filters of multiple scales or aspect ratios.</li>
</ul>

<h4 id="ssd-fpn">SSD / FPN</h4>

<p><img src="https://www.yuthon.com/images/FFRMR_ssd_fpn.jpg" alt="SSD and FPN" /></p>

<ul>
<li><strong>FPN (Feature Pyramid Network)</strong> exploit the inherent multi-scale, pyramidal hierarchy of deep convolutional networks to construct feature pyramids with marginal extra cost. A top-down architecture with lateral connections is developed for building high-level semantic feature maps at all scales.</li>
</ul>

<h3 id="instance-segmentation">Instance Segmentation</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_instance_segmentation.jpg" alt="Instance Segmentation" /></p>

<ul>
<li>Use <strong>Mask Regression</strong> to predict instance segmentation based on object bounding box.</li>
<li>Replace RoI Pooling with <strong>RoI Align</strong></li>
</ul>

<h3 id="keypoint-detection">Keypoint Detection</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_keypoint_detection.jpg" alt="Keypoint Detection" /></p>

<ul>
<li>We make minor modifications to the segmentation system when adapting it for keypoints.</li>
<li>For each of the $K$ keypoints of an instance, the training target is a one-hot $m \times m$ binary mask where only a single pixel is labeled as foreground.</li>
</ul>

<h2 id="today-details-about-mask-rcnn-and-comparisons">Today - details about Mask-RCNN and comparisons</h2>

<h3 id="roi-align">RoI Align</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_roi_align_1.jpg" alt="RoI Align 1" /></p>

<ul>
<li>RoI pooling contains two step of coordinates quantization: from original image into feature map (divide by stride) and from feature map into roi feature (use grid). <strong>Those quantizations cause a huge loss of location precision.</strong>

<ul>
<li>e.g. we have two boxes whose coordinate are 1.1 and 2.2, and the stride of feature map is 16, then they&rsquo;re the same in the feature map.</li>
</ul></li>
<li><strong>RoI Align</strong> remove those two quantizations, and <strong>manipulate coordinates on continuous domain</strong>, which increase the location accuracy greatly.</li>
</ul>

<p><img src="https://www.yuthon.com/images/FFRMR_table_of_mask_rcnn.jpg" alt="Ablations for Mask R-CNN" /></p>

<ul>
<li>RoI Align really improves the result.</li>
<li>Moreover, note that with RoIAlign, using stride-32 C5 features (30.9 AP) is more accurate than using stride-16 C4 features (30.3 AP, Table 2c). <strong>RoIAlign largely resolves the long-standing challenge of using large-stride features for detection and segmentation.</strong>

<ul>
<li>Without RoIAlign, AP in ResNet-50-C4 is better than that in C5 with RoIPooling, i.e., large stride is worse.Thus many precious work try to find methods to get better results in smaller stride. Now with RoIAlign, we can consider whether to use those tricks.</li>
</ul></li>
</ul>

<h3 id="multinomial-vs-independent-masks">Multinomial vs. Independent Masks</h3>

<ul>
<li><strong>Replace softmax with sigmoid</strong>.

<ul>
<li>Mask R-CNN decouples mask and class prediction: as the existing box branch predicts the class label, we generate a mask for each class without competition among classes (by a per-pixel sigmoid and a binary loss).</li>
<li>In Table 2b, we compare this to using a per-pixel softmax and a multinomial loss (as com- monly used in FCN). This alternative couples the tasks of mask and class prediction, and results in a severe loss in mask AP (5.5 points).</li>
<li>The result suggests that <strong>once the instance has been classified as a whole (by the box branch), it is sufficient to predict a binary mask without concern for the categories</strong>, which makes the model easier to train.</li>
</ul></li>
</ul>

<h3 id="multi-task-cascade-vs-joint-learning">Multi-task Cascade vs. Joint Learning</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_multitask_cascase_vs_joint_learning.jpg" alt="Multi-task Cascade vs. Joint Learning" /></p>

<ul>
<li>Cascading and paralleling are adopted alternately.</li>
<li>On training time, three tasks of Mask R-CNN are <strong>paralleling trained</strong>.</li>
<li>But <strong>on testing time, we do classification and bbox regression first, and then use those results to get masks</strong>.

<ul>
<li>BBox regression may change the location of bbox, so we should wait it to be done.</li>
<li>After bbox regression, we may adopt NMS or other methods to reduce the number of boxes. That decreases the workload of segmenting masks.</li>
</ul></li>
<li><strong>Adding the mask branch</strong> to the box-only (i.e., Faster R-CNN) or keypoint-only versions consistently <strong>improves these tasks</strong>.

<ul>
<li>However, adding the keypoint branch reduces the box/mask AP slightly, suggest- ing that while keypoint detection benefits from multitask training, it does not in turn help the other tasks.</li>
<li>Nevertheless, learning all three tasks jointly enables a unified system to efficiently predict all outputs simultaneously (Figure 6).</li>
</ul></li>
</ul>

<p><img src="https://www.yuthon.com/images/FFRMR_table_of_mask_rcnn_2.jpg" alt="Table for Mask R-CNN" /></p>

<h3 id="comparison-on-human-keypoints">Comparison on Human Keypoints</h3>

<ul>
<li>Table 4 shows that our result (62.7 APkp) is 0.9 pointshigher than the COCO 2016 keypoint detection winner [4]that uses a multi-stage processing pipeline (see caption ofTable 4). Our method is considerably simpler and faster.</li>
<li>More importantly, we have a unified model that can si-multaneously predict boxes, segments, and keypoints whilerunning at 5 fps.</li>
</ul>

<h3 id="results">Results</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_keypoint_detection_result.jpg" alt="Keypoint detection results" /></p>

<p><img src="https://www.yuthon.com/images/FFRMR_mask_rcnn_results.jpg" alt="More results of Mask R-CNN on COCO test images" /></p>

<h2 id="future-discussion">Future - discussion</h2>

<h3 id="order-of-key-functions">Order of key functions?</h3>

<ul>
<li>Order of classification, localization, mask classification and landmarks localization?</li>
<li>Top down or Buttom up?

<ul>
<li>Mask R-CNN uses Top-down method.</li>
<li>the COCO 2016 keypoint detection winner CMU-Pose+++ uses Buttom-up method.</li>
<li>Detect key points first (don&rsquo;t know which keypoint belongs to which person)&rsquo;</li>
<li>Then gradually stitch them together</li>
</ul></li>
</ul>

<h3 id="precious-semantic-label">Precious &amp; semantic label</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_precious_and_semantic_label.jpg" alt="Precious &amp; semantic label" /></p>

<p>box-level label -&gt; instance segmentation &amp; keypoints detection -&gt; instance seg with body parts</p>

<h3 id="semantic-3d-reconstruction">Semantic 3D reconstruction</h3>

<p><img src="https://www.yuthon.com/images/FFRMR_semantic_reconstruction.jpg" alt="Semantic 3D reconstruction" /></p>

<h3 id="future">Future</h3>

<ul>
<li>the performance &amp; system improves rapidly</li>
<li>join a team, keep going</li>
<li>always try, thinking and discussion</li>
<li>understand and structure the world</li>
</ul>
    </div>

    <div class="post-copyright">
  <p class="copyright-item">
    <span class="item-title">Author</span>
    <span class="item-content">Yusu Pan</span>
  </p>
  <p class="copyright-item">
    <span class="item-title">LastMod</span>
    <span class="item-content">
        2017-04-27
        
    </span>
  </p>
  
  <p class="copyright-item">
    <span class="item-title">License</span>
    <span class="item-content"><a rel="license noopener" href="https://creativecommons.org/licenses/by-nc-nd/4.0/" target="_blank">CC BY-NC-ND 4.0</a></span>
  </p>
</div>
<footer class="post-footer">
      <div class="post-tags">
          <a href="https://www.yuthon.com/tags/object-detection/">Object Detection</a>
          <a href="https://www.yuthon.com/tags/semantic-segmentation/">Semantic Segmentation</a>
          <a href="https://www.yuthon.com/tags/faster-r-cnn/">Faster R-CNN</a>
          <a href="https://www.yuthon.com/tags/mask-r-cnn/">Mask R-CNN</a>
          </div>
      <nav class="post-nav">
        <a class="prev" href="https://www.yuthon.com/post/papers/notes-for-sec/">
            <i class="iconfont icon-left"></i>
            <span class="prev-text nav-default">Notes for SEC</span>
            <span class="prev-text nav-mobile">Prev</span>
          </a>
        <a class="next" href="https://www.yuthon.com/post/practices/tensorflow-r1-0-on-tx1/">
            <span class="next-text nav-default">TensorFlow r1.0 on TX1 (now successful)</span>
            <span class="next-text nav-mobile">Next</span>
            <i class="iconfont icon-right"></i>
          </a>
      </nav>
    </footer>
  </article>
        </div>
        <div id="disqus_thread"></div>
    <script type="text/javascript">
    (function() {
      
      
      if (window.location.hostname === 'localhost') return;

      var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
      var disqus_shortname = 'yuthons-blog';
      dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
      (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
    </script>
    <noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>

      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="social-links">
      <a href="mailto:xxdsox@gmail.com" class="iconfont icon-email" title="email"></a>
      <a href="https://stackoverflow.com/users/5682817" class="iconfont icon-stack-overflow" title="stack-overflow"></a>
      <a href="https://twitter.com/corenel" class="iconfont icon-twitter" title="twitter"></a>
      <a href="https://www.facebook.com/xxdsox" class="iconfont icon-facebook" title="facebook"></a>
      <a href="https://github.com/corenel" class="iconfont icon-github" title="github"></a>
      <a href="https://www.zhihu.com/people/pan-yu-su" class="iconfont icon-zhihu" title="zhihu"></a>
  <a href="https://www.yuthon.com/index.xml" type="application/rss+xml" class="iconfont icon-rss" title="rss"></a>
</div>

<div class="copyright">
  <span class="power-by">
    Powered by <a class="hexo-link" href="https://gohugo.io">Hugo</a>
  </span>
  <span class="division">|</span>
  <span class="theme-info">
    Theme - 
    <a class="theme-link" href="https://github.com/olOwOlo/hugo-theme-even">Even</a>
  </span>

  

  <span class="copyright-year">
    &copy; 
    2017 - 
    2019
    <span class="heart">
      <i class="iconfont icon-heart"></i>
    </span>
    <span class="author">© This post is licensed under a Creative Commons Attribution-NonCommercial 4.0 International License, please give source if you wish to quote or reproduce.
</span>
  </span>
</div>
    </footer>

    <div class="back-to-top" id="back-to-top">
      <i class="iconfont icon-up"></i>
    </div>
  </div>
  
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.2.1/dist/jquery.min.js" integrity="sha256-hwg4gsxgFZhOsEEamdOYGBf13FyQuiTwlAQgxVSNgt4=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/slideout@1.0.1/dist/slideout.min.js" integrity="sha256-t+zJ/g8/KXIJMjSVQdnibt4dlaDxc9zXr/9oNPeWqdg=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@3.1.20/dist/jquery.fancybox.min.js" integrity="sha256-XVLffZaxoWfGUEbdzuLi7pwaUJv1cecsQJQqGLe7axY=" crossorigin="anonymous"></script>
<script type="text/javascript" src="https://www.yuthon.com/dist/even.26188efa.min.js"></script>
  <script type="text/javascript">
    window.MathJax = {
      tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]},
      TeX: {equationNumbers: {autoNumber: "AMS"}},
      showProcessingMessages: false,
      messageStyle: 'none'
    };
  </script>
  <script type="text/javascript" async src="https://www.yuthon.com/lib/mathjax/math-code.js"></script>
    <script async src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/MathJax.js?config=TeX-MML-AM_CHTML"  integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>


<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-76233259-1', 'auto');
	ga('set', 'anonymizeIp', true);
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>







</body>
</html>
